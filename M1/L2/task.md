1.  Загрузите набор данных `lenta-ru-news` с помощью библиотеки `Corus` или любым другим способом для задачи классификации текстов по топикам (пригодятся атрибуты `title`, `text`, `topic`)

2.  Подготовьте данные к обучению — 2 балла
    - Предобработайте данные: реализуйте оптимальную, на ваш взгляд, предобработку текстов (нормализация, очистка, стемминг/лемматизация и т.п.) и таргета.
    - *hint: для ускорения обработки и обучения можно ограничиться не всем датасетом, а его репрезентативной частью, например, размера 100_000.*
    - Кратко опишите пайплайн, на котором остановились, и почему.
    - Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции 60/20/20. В качестве целевой переменной используйте атрибут `topic`

3.  Обучите модель `sklearn.linear_model.LogisticRegression` с двумя вариантами векторизации — 2 балла
    - `sklearn.feature_extraction.text.CountVectorizer`
    - `sklearn.feature_extraction.text.TfidfVectorizer`

4.  Попробуйте улучшить качество, подобрав оптимальные гиперпараметры трансформаций и модели на кросс-валидации — 1 балл

5.  Обучите word2vec-эмбеддинги с помощью библиотеки `gensim` — 2 балла
    - создайте модель для обучения на ваших данных, опишите, какими значениями вы инициализировали гиперпараметры модели, и почему
    - визуально оцените внутреннее (intrinsic) качество получившихся эмбеддингов, используя методы `gensim` — `doesnt_match`, `most_similar`

6.  Загрузите предобученные эмбеддинги из `navec` или `rusvectores` (на ваш вкус) — 1 балл

7.  Обучите модель `sklearn.linear_model.LogisticRegression` с обученными и загруженными эмбеддингами, сравните их качество между собой на валидационной выборке — 1 балл
    - ваши эмбеддинги `w2v`
    - предобученные эмбеддинги `navec`/`rusvectores`

8.  Финально сравните качество всех моделей на тестовой выборке — 1 балл