{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from IPython.display import Markdown, display\n",
    "from peft import LoraConfig, PeftModel, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses, util\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4bf3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Глобальные переменные\n",
    "rstate = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e10313",
   "metadata": {},
   "source": [
    "# Задание 1: Дообучение декодерной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5677bf7",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных и модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5b2a4",
   "metadata": {},
   "source": [
    "### 1.1. Выбор и загрузка датасета\n",
    "\n",
    "Используем датасет с отзывами на фильмы с Кинопоиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8c5f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"blinoff/kinopoisk\"\n",
    "local_dataset_path = \"./kinopoisk_dataset_local\"\n",
    "\n",
    "if os.path.exists(local_dataset_path):\n",
    "    dataset = load_from_disk(local_dataset_path)\n",
    "else:\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    dataset.save_to_disk(local_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "### 1.2. Выбор и загрузка предобученной модели\n",
    "\n",
    "В качестве базовой модели выберем `ai-forever/mGPT` (1.3B параметров), которая является хорошим компромиссом между размером и доступными ресурсами. \n",
    "\n",
    "Для дообучения будем использовать QLoRA, поэтому сразу настроим 4-битную квантизацию при загрузке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5g6h7i8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./mGPT_local\"  # локальная копию ai-forever/mGPT\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, quantization_config=bnb_config, device_map={\"\": 0}, trust_remote_code=True\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### 1.3. Предварительная обработка данных\n",
    "\n",
    "Проанализируем распределение длин текстов, чтобы выбрать оптимальную длину контекста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "m3n4o5p6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2375 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_split = dataset[\"train\"]\n",
    "\n",
    "text_lengths = [len(tokenizer.encode(html.unescape(text))) for text in train_split[\"content\"]]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(text_lengths, bins=50)\n",
    "plt.title(\"Распределение длин текстов в токенах\")\n",
    "plt.xlabel(\"Количество токенов\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c48ca5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем сбалансированный размер, покрывающий больше половины датасета, но\n",
    "# приемлимый для обучения на имеющихся вычислительной мощности\n",
    "context_length = 512\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        html.unescape(examples[\"content\"]), padding=\"max_length\", truncation=True, max_length=context_length\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_dataset = train_split.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_split.column_names,\n",
    ")\n",
    "\n",
    "train_val_split = tokenized_dataset.train_test_split(test_size=0.1, seed=rstate)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "# 2. Предварительная оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Результат генерации ДО дообучения: ---\n",
      "Промпт: Этот фильм был просто\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Этот фильм был просто великолепен. Он был снят в очень хорошем качестве, и я не могу сказать, что я ожидал от него больше. Я не ожидала, чтобы он был настолько хорошим, как это было\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Промпт: Актерская игра была на высоте, особенно\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Актерская игра была на высоте, особенно в роли Саши.\n",
       "Спасибо за фильм, очень понравился. Спаасибки за рецензию.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Промпт: Я не рекомендую этот фильм, потому что\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Я не рекомендую этот фильм, потому что он не очень хорош.\n",
       "Вот такая история. Вот такой фильм. И вот такую историю. Но, как говорится, не надо забывать, что все мы\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Функция генерации текста\n",
    "def generate_text(model, tokenizer, prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(\"--- Результат генерации ДО дообучения: ---\")\n",
    "\n",
    "prompts = [\"Этот фильм был просто\", \"Актерская игра была на высоте, особенно\", \"Я не рекомендую этот фильм, потому что\"]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Промпт: {prompt}\")\n",
    "    generated_text = generate_text(model, tokenizer, prompt)\n",
    "    display(Markdown(f\"> {generated_text}\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y5z6a7b8",
   "metadata": {},
   "source": [
    "### Оценка с помощью lm-evaluation-harness\n",
    "\n",
    "Для оценки на стандартных бенчмарках используем `lm-evaluation-harness`. Мы запустим его для задачи `hellaswag_ru`. Эта задача оценивает возможность модели оценивать логическое продолжение предложения из промта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad4ab2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-25:13:41:11 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-12-25:13:41:11 INFO     [__main__:465] Selected Tasks: ['hellaswag_ru']\n",
      "2025-12-25:13:41:11 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-12-25:13:41:11 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': './mGPT_local', 'trust_remote_code': True, 'max_length': 2048, 'dtype': 'float16'}\n",
      "2025-12-25:13:41:11 INFO     [models.huggingface:158] Using device 'cuda:0'\n",
      "2025-12-25:13:41:11 INFO     [models.huggingface:420] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "2025-12-25:13:41:17 INFO     [tasks:695] Selected tasks:\n",
      "2025-12-25:13:41:17 INFO     [tasks:686] Task: hellaswag_ru (okapi/hellaswag_multilingual/hellaswag_ru.yaml)\n",
      "2025-12-25:13:41:17 INFO     [api.task:434] Building contexts for hellaswag_ru on rank 0...\n",
      "100%|███████████████████████████████████| 4000/4000 [00:00<00:00, 113089.07it/s]\n",
      "2025-12-25:13:41:17 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████| 16000/16000 [04:29<00:00, 59.42it/s]\n",
      "2025-12-25:13:45:55 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=./mGPT_local,trust_remote_code=True,max_length=2048,dtype=float16), gen_kwargs: (None), limit: 4000.0, num_fewshot: None, batch_size: 4\n",
      "|   Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
      "|hellaswag_ru|      1|none  |     0|acc     |↑  |0.2993|±  |0.0072|\n",
      "|            |       |none  |     0|acc_norm|↑  |0.3295|±  |0.0074|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=./mGPT_local,trust_remote_code=True,max_length=2048,dtype=\"float16\" \\\n",
    "    --tasks hellaswag_ru \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 4 \\\n",
    "    --limit 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aef5ce",
   "metadata": {},
   "source": [
    "**Выводы:** базовая модель показала на тесте HellaSwag нормализованную точность 0.3295, что уверенно превышает порог случайного угадывания (0.25). Этот результат фиксируется как отправная точка для проверки того, не разрушит ли дообучение общую логику и \"здравый смысл\" модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "# 3. QLoRA-дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3h4i5j6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3145728 || all params: 816762880 || trainable%: 0.38514580878112387\n"
     ]
    }
   ],
   "source": [
    "# Готовим модель к обучению\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Конфигурация LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    # ВАЖНО: для mGPT используем c_attn\n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "k7l8m9n0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем дообучение модели...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 2:32:04, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.514700</td>\n",
       "      <td>2.425513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.485100</td>\n",
       "      <td>2.385436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.453100</td>\n",
       "      <td>2.368608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.447300</td>\n",
       "      <td>2.359834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.437600</td>\n",
       "      <td>2.356457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дообучение завершено.\n"
     ]
    }
   ],
   "source": [
    "# Отключаем встроенный параллелизм токенизатора, чтобы не конфликтовал с DataLoader\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mgpt_kinopoisk_generator\",\n",
    "    # --- Ограничение времени обучения ---\n",
    "    # Для задачи адаптации стиля возьмем умеренное количество шагов:\n",
    "    max_steps=1000,\n",
    "    # --- Стратегия сохранения и оценки ---\n",
    "    # Так как мы не покрываем полную эпоху, то будем оценивать качество и сохранять чекпоинт\n",
    "    # каждые 200 шагов. Всего будем хранить не более 2 чекпоинтов, чтобы иметь возможность выбрать лучший.\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    # --- Параметры оптимизации ---\n",
    "    # Эмпирическая оценка. 2e-4 — \"золотой стандарт\" для обучения адаптеров LoRA.\n",
    "    learning_rate=2e-4,\n",
    "    # Снизим точность, чтобы поместиться в 8 Гб имеющейся видеопамяти\n",
    "    fp16=True,\n",
    "    # --- Размеры батча ---\n",
    "    # Подберем размеры батчей и количество накоплений шагов градиента для максимальной утилизации вычислительной мощности\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    # --- Прочее ---\n",
    "    dataloader_num_workers=4,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Начинаем дообучение модели...\")\n",
    "trainer.train()\n",
    "print(\"Дообучение завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dc23f",
   "metadata": {},
   "source": [
    "## Сохранение дообученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "898f8233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Адаптеры сохранены в ./mgpt_kinopoisk_lora_adapters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем адаптеры и объединяем...\n",
      "Полная модель успешно сохранена в: ./mgpt_kinopoisk_finetuned_full\n"
     ]
    }
   ],
   "source": [
    "# 1. Сохраняем веса LoRA и токенизатор\n",
    "adapter_path = \"./mgpt_kinopoisk_lora_adapters\"\n",
    "trainer.save_model(adapter_path)\n",
    "tokenizer.save_pretrained(adapter_path)\n",
    "print(f\"Адаптеры сохранены в {adapter_path}\")\n",
    "\n",
    "# 2. Очищаем память от старой модели\n",
    "del model, trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3. Загружаем базовую модель\n",
    "base_model_name = \"./mGPT_local\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name, torch_dtype=torch.float16, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 4. Накладываем на нее ваши обученные адаптеры\n",
    "adapter_path = \"./mgpt_kinopoisk_generator/checkpoint-1000\"\n",
    "print(\"Загружаем адаптеры и объединяем...\")\n",
    "model_to_merge = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "\n",
    "# 5. Физическое слияние весов\n",
    "merged_model = model_to_merge.merge_and_unload()\n",
    "\n",
    "# 6. Сохраняем готовую модель\n",
    "output_merged_dir = \"./mgpt_kinopoisk_finetuned_full\"\n",
    "merged_model.save_pretrained(output_merged_dir)\n",
    "tokenizer.save_pretrained(output_merged_dir)\n",
    "print(f\"Полная модель успешно сохранена в: {output_merged_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342e15e",
   "metadata": {},
   "source": [
    "## Загрузка дообученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc643538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаю модель из ./mgpt_kinopoisk_finetuned_full...\n",
      "Дообученная модель успешно загружена!\n"
     ]
    }
   ],
   "source": [
    "finetuned_model_path = \"./mgpt_kinopoisk_finetuned_full\"\n",
    "\n",
    "print(f\"Загружаю модель из {finetuned_model_path}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    finetuned_model_path,\n",
    "    dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "print(\"Дообученная модель успешно загружена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "# 4. Оценка качества обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18a60638",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Этот фильм был просто\", \"Актерская игра была на высоте, особенно\", \"Я не рекомендую этот фильм, потому что\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "s5t6u7v8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Результат генерации ПОСЛЕ дообучения: ---\n",
      "Промпт: Этот фильм был просто\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Этот фильм был просто замечательный! Я просто в конце фильма просто замерла и когда его просмотрела, я была вам за.\n",
       "\n",
       "У меня такая же разница в\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Промпт: Актерская игра была на высоте, особенно\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Актерская игра была на высоте, особенно в «Донбассе», где потрясающие актеры играли свои роли. В «Зелёном ящике» тоже отлично сыграли.\n",
       "\n",
       "Напоследок хочу сказать,\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Промпт: Я не рекомендую этот фильм, потому что\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Я не рекомендую этот фильм, потому что в фильме есть всё своё и иже с тем, что, в помимо всего прочего, это кусочек мульта, который так же является хорошим примером того, как\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"--- Результат генерации ПОСЛЕ дообучения: ---\")\n",
    "\n",
    "\n",
    "# Фунция для генерации ответа\n",
    "def generate_text(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Промпт: {prompt}\")\n",
    "    generated_text = generate_text(finetuned_model, tokenizer, prompt)\n",
    "    display(Markdown(f\"> {generated_text}\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9x0y1z2",
   "metadata": {},
   "source": [
    "### Оценка с помощью lm-evaluation-harness\n",
    "\n",
    "Аналогично проверке базовой модеои - запустим `lm-evaluation-harness` для задачи `hellaswag_ru`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "538c0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-25:16:40:42 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-12-25:16:40:42 INFO     [__main__:465] Selected Tasks: ['hellaswag_ru']\n",
      "2025-12-25:16:40:42 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-12-25:16:40:42 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': './mgpt_kinopoisk_finetuned_full', 'trust_remote_code': True, 'max_length': 2048,\n",
      "        'dtype': 'float16'}\n",
      "2025-12-25:16:40:42 INFO     [models.huggingface:158] Using device 'cuda:0'\n",
      "2025-12-25:16:40:42 INFO     [models.huggingface:420] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
      "2025-12-25:16:40:47 INFO     [tasks:695] Selected tasks:\n",
      "2025-12-25:16:40:47 INFO     [tasks:686] Task: hellaswag_ru (okapi/hellaswag_multilingual/hellaswag_ru.yaml)\n",
      "2025-12-25:16:40:47 INFO     [api.task:434] Building contexts for hellaswag_ru on rank 0...\n",
      "100%|████████████████████████████████████| 4000/4000 [00:00<00:00, 94337.23it/s]\n",
      "2025-12-25:16:40:48 INFO     [evaluator:574] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████| 16000/16000 [04:35<00:00, 58.06it/s]\n",
      "2025-12-25:16:45:34 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=./mgpt_kinopoisk_finetuned_full,trust_remote_code=True,max_length=2048,dtype=float16), gen_kwargs: (None), limit: 4000.0, num_fewshot: None, batch_size: 4\n",
      "|   Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
      "|------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
      "|hellaswag_ru|      1|none  |     0|acc     |↑  |0.2960|±  |0.0072|\n",
      "|            |       |none  |     0|acc_norm|↑  |0.3292|±  |0.0074|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=./mgpt_kinopoisk_finetuned_full,trust_remote_code=True,max_length=2048,dtype=\"float16\" \\\n",
    "    --tasks hellaswag_ru \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 4 \\\n",
    "    --limit 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "1. Количественная оценка (HellaSwag Ru) - для контроля общего уровня «интеллекта» модели и проверки на катастрофическое забывание использовался бенчмарк hellaswag_ru (задача на здравый смысл и продолжение текста).\n",
    "\n",
    "    Получены результаты:\n",
    "- До обучения: acc_norm = 0.3295 (±0.0074)\n",
    "- После обучения: acc_norm = 0.3277 (±0.0074)\n",
    "\n",
    "    Падение на 0.0018 близко к статистической погрешности. Модель сохранила свои общие знания и способность связно продолжать текст.\n",
    "\n",
    "2. Качественная оценка (Генерация текста) - cравнение генерации на одних и тех же промптах показывает явный сдвиг в доменную область:\n",
    "\n",
    "    Базовая модель: Генерировала тексты общего характера, иногда сваливаясь в повторы или теряя контекст рецензии (например, фразы «Спаасибки за рецензию»).\n",
    "\n",
    "    Дообученная модель: Успешно переняла стилистику пользователей Кинопоиска. Однако из-за ограничений самой модели, количества вычислительных мощностей или самого QLoRA подхода к дообучению - изменения практически незаметны без вдумчивого и пословного сравнения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a9d49",
   "metadata": {},
   "source": [
    "# Задание 2: Дообучение энкодерной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder-task-def",
   "metadata": {},
   "source": [
    "## 1-2. Выбор датасета и модели\n",
    "\n",
    "**Датасет:** `kuznetsoffandrey/sberquad` - датасет с парами \"вопрос-ответ\".\n",
    "\n",
    "**Модель:** `cointegrated/rubert-tiny2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "encoder-load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено и обработано 45328 пар вопрос-ответ.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "520e23c9-c89e-4a96-87cf-76b20316feff",
       "rows": [
        [
         "0",
         "62310",
         "SberChallenge",
         "В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.",
         "чем представлены органические остатки?",
         "{'text': array(['известковыми выделениями сине-зелёных водорослей'], dtype=object), 'answer_start': array([109], dtype=int32)}",
         "известковыми выделениями сине-зелёных водорослей"
        ],
        [
         "1",
         "28101",
         "SberChallenge",
         "В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.",
         "что найдено в кремнистых сланцах железорудной формации Канады?",
         "{'text': array(['нитевидные водоросли, грибные нити'], dtype=object), 'answer_start': array([438], dtype=int32)}",
         "нитевидные водоросли, грибные нити"
        ],
        [
         "2",
         "48834",
         "SberChallenge",
         "В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.",
         "что встречается в протерозойских отложениях?",
         "{'text': array(['органические остатки'], dtype=object), 'answer_start': array([28], dtype=int32)}",
         "органические остатки"
        ],
        [
         "3",
         "83056",
         "SberChallenge",
         "В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.",
         "что относится к числу древнейших растительных остатков?",
         "{'text': array(['скопления графито-углистого вещества'], dtype=object), 'answer_start': array([283], dtype=int32)}",
         "скопления графито-углистого вещества"
        ],
        [
         "4",
         "5816",
         "SberChallenge",
         "В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они представлены известковыми выделениями сине-зелёных водорослей, ходами червей, остатками кишечнополостных. Кроме известковых водорослей, к числу древнейших растительных остатков относятся скопления графито-углистого вещества, образовавшегося в результате разложения Corycium enigmaticum. В кремнистых сланцах железорудной формации Канады найдены нитевидные водоросли, грибные нити и формы, близкие современным кокколитофоридам. В железистых кварцитах Северной Америки и Сибири обнаружены железистые продукты жизнедеятельности бактерий.",
         "как образовалось графито-углистое вещество?",
         "{'text': array(['в результате разложения Corycium enigmaticum'], dtype=object), 'answer_start': array([337], dtype=int32)}",
         "в результате разложения Corycium enigmaticum"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62310</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>чем представлены органические остатки?</td>\n",
       "      <td>{'text': ['известковыми выделениями сине-зелён...</td>\n",
       "      <td>известковыми выделениями сине-зелёных водорослей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28101</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>что найдено в кремнистых сланцах железорудной ...</td>\n",
       "      <td>{'text': ['нитевидные водоросли, грибные нити'...</td>\n",
       "      <td>нитевидные водоросли, грибные нити</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48834</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>что встречается в протерозойских отложениях?</td>\n",
       "      <td>{'text': ['органические остатки'], 'answer_sta...</td>\n",
       "      <td>органические остатки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83056</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>что относится к числу древнейших растительных ...</td>\n",
       "      <td>{'text': ['скопления графито-углистого веществ...</td>\n",
       "      <td>скопления графито-углистого вещества</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5816</td>\n",
       "      <td>SberChallenge</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>как образовалось графито-углистое вещество?</td>\n",
       "      <td>{'text': ['в результате разложения Corycium en...</td>\n",
       "      <td>в результате разложения Corycium enigmaticum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          title                                            context  \\\n",
       "0  62310  SberChallenge  В протерозойских отложениях органические остат...   \n",
       "1  28101  SberChallenge  В протерозойских отложениях органические остат...   \n",
       "2  48834  SberChallenge  В протерозойских отложениях органические остат...   \n",
       "3  83056  SberChallenge  В протерозойских отложениях органические остат...   \n",
       "4   5816  SberChallenge  В протерозойских отложениях органические остат...   \n",
       "\n",
       "                                            question  \\\n",
       "0             чем представлены органические остатки?   \n",
       "1  что найдено в кремнистых сланцах железорудной ...   \n",
       "2       что встречается в протерозойских отложениях?   \n",
       "3  что относится к числу древнейших растительных ...   \n",
       "4        как образовалось графито-углистое вещество?   \n",
       "\n",
       "                                             answers  \\\n",
       "0  {'text': ['известковыми выделениями сине-зелён...   \n",
       "1  {'text': ['нитевидные водоросли, грибные нити'...   \n",
       "2  {'text': ['органические остатки'], 'answer_sta...   \n",
       "3  {'text': ['скопления графито-углистого веществ...   \n",
       "4  {'text': ['в результате разложения Corycium en...   \n",
       "\n",
       "                                             answer  \n",
       "0  известковыми выделениями сине-зелёных водорослей  \n",
       "1                нитевидные водоросли, грибные нити  \n",
       "2                              органические остатки  \n",
       "3              скопления графито-углистого вещества  \n",
       "4      в результате разложения Corycium enigmaticum  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_dataset = load_dataset(\"kuznetsoffandrey/sberquad\")\n",
    "encoder_df = encoder_dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Извлечем текстовые ответы и создадим новую колонку 'answer'\n",
    "encoder_df[\"answer\"] = encoder_df[\"answers\"].apply(lambda x: x[\"text\"][0] if len(x[\"text\"]) > 0 else \"\")\n",
    "\n",
    "# Удалим строки, где не удалось извлечь ответ\n",
    "encoder_df = encoder_df[encoder_df[\"answer\"] != \"\"].copy()\n",
    "\n",
    "print(f\"Загружено и обработано {len(encoder_df)} пар вопрос-ответ.\")\n",
    "encoder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "encoder-load-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 29,952 || all params: 29,223,720 || trainable%: 0.1025\n"
     ]
    }
   ],
   "source": [
    "base_encoder_model_name = \"cointegrated/rubert-tiny2\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. Загрузим базовую модель\n",
    "st_model = SentenceTransformer(base_encoder_model_name, device=device)\n",
    "\n",
    "# Извлекаем базовый AutoModel из SentenceTransformer\n",
    "backbone = st_model[0].auto_model\n",
    "\n",
    "# Включаем gradient checkpointing\n",
    "if hasattr(backbone, \"gradient_checkpointing_enable\"):\n",
    "    backbone.gradient_checkpointing_enable()\n",
    "\n",
    "# 2. Конфигурация LoRA\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    ")\n",
    "\n",
    "# Применяем LoRA к backbone модели\n",
    "peft_backbone = get_peft_model(backbone, lora_cfg)\n",
    "peft_backbone.print_trainable_parameters()\n",
    "\n",
    "# 3. Заменяем оригинальный backbone на PEFT-обернутый\n",
    "st_model[0].auto_model = peft_backbone\n",
    "\n",
    "# Токенизатор SentenceTransformer будет работать с PEFT-моделью\n",
    "encoder_tokenizer = st_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder-eval-explain",
   "metadata": {},
   "source": [
    "## 3. Предварительная оценка качества\n",
    "\n",
    "Для оценки качества будем использовать метрику **Accuracy@k**. \n",
    "\n",
    "**Логика:**\n",
    "1. Создадим тестовую выборку из 1000 примеров.\n",
    "2. Вопросы (`queries`) и ответы (`corpus`) из этой выборки будут использоваться для поиска.\n",
    "3. Для каждого вопроса мы будем искать наиболее похожий на него текст в корпусе всех ответов.\n",
    "4. Если правильный ответ на вопрос попадает в `k` наиболее похожих ответов из корпуса, то считаем, что модель справилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "encoder-eval-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Оценка базовой модели ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b086cd335564fa18eab8b2b23d3877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy@1': np.float64(0.09), 'accuracy@3': np.float64(0.143), 'accuracy@5': np.float64(0.177)}\n"
     ]
    }
   ],
   "source": [
    "# Функция-обертка для получения эмбеддингов предложений\n",
    "def get_sentence_embeddings(texts, model, batch_size=32):\n",
    "    # SentenceTransformer.encode умеет работать со списками\n",
    "    return model.encode(texts, convert_to_tensor=True, show_progress_bar=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "eval_df = encoder_df.sample(1000, random_state=rstate)\n",
    "corpus = eval_df[\"answer\"].tolist()\n",
    "queries = eval_df[\"question\"].tolist()\n",
    "relevant_docs = {queries[i]: {corpus[i]} for i in range(len(queries))}\n",
    "\n",
    "\n",
    "def evaluate_model(model, queries, corpus, relevant_docs, k_values=[1, 3, 5]):\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        results[f\"accuracy@{k}\"] = 0\n",
    "\n",
    "    corpus_embeddings = get_sentence_embeddings(corpus, model)\n",
    "\n",
    "    for i, query in enumerate(tqdm(queries)):\n",
    "        query_embedding = get_sentence_embeddings(query, model)\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=max(k_values))\n",
    "\n",
    "        for k in k_values:\n",
    "            top_k_indices = top_results.indices[:k]\n",
    "            top_k_docs = [corpus[idx.item()] for idx in top_k_indices]\n",
    "            if relevant_docs[query].intersection(set(top_k_docs)):\n",
    "                results[f\"accuracy@{k}\"] += 1\n",
    "\n",
    "    for k in k_values:\n",
    "        results[f\"accuracy@{k}\"] = np.round(results[f\"accuracy@{k}\"] / len(queries), 4)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"--- Оценка базовой модели ---\")\n",
    "base_model_results = evaluate_model(st_model, queries, corpus, relevant_docs)\n",
    "print(base_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder-train-explain",
   "metadata": {},
   "source": [
    "# 3. QLoRA-дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "encoder-train-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dd4d3c2d394087b193b22e1ff66f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем QLoRA-дообучение энкодера...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 03:27, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.604700</td>\n",
       "      <td>1.159778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.081700</td>\n",
       "      <td>0.805560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.821600</td>\n",
       "      <td>0.716683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.703300</td>\n",
       "      <td>0.680696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.615800</td>\n",
       "      <td>0.658630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.632900</td>\n",
       "      <td>0.642534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.591500</td>\n",
       "      <td>0.633162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.531800</td>\n",
       "      <td>0.628152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.567400</td>\n",
       "      <td>0.623049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.574300</td>\n",
       "      <td>0.621184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.577400</td>\n",
       "      <td>0.620460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.593100</td>\n",
       "      <td>0.620316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дообучение завершено.\n"
     ]
    }
   ],
   "source": [
    "# 1. Подготовка данных\n",
    "train_df = encoder_df.drop(eval_df.index)\n",
    "\n",
    "train_examples = []\n",
    "for i, row in train_df.iterrows():\n",
    "    train_examples.append(InputExample(texts=[row[\"question\"], row[\"answer\"]]))\n",
    "\n",
    "train_ds = Dataset.from_list([{\"anchor\": ex.texts[0], \"positive\": ex.texts[1]} for ex in train_examples])\n",
    "\n",
    "val_examples = []\n",
    "for i, row in eval_df.iterrows():  # eval_df used for validation here, as in the example\n",
    "    val_examples.append(InputExample(texts=[row[\"question\"], row[\"answer\"]]))\n",
    "\n",
    "val_ds = Dataset.from_list([{\"anchor\": ex.texts[0], \"positive\": ex.texts[1]} for ex in val_examples])\n",
    "\n",
    "\n",
    "# 2. Настройка обучения\n",
    "epochs = 5\n",
    "batch_size = 32  # Модель небольшая, возьмем увеличенный размер батча\n",
    "max_steps_cap = 120\n",
    "\n",
    "steps_per_epoch = min(math.ceil(len(train_ds) / batch_size), max_steps_cap)\n",
    "total_steps = steps_per_epoch * epochs\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=st_model)\n",
    "\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"./rubert-tiny2-qa-lora-finetuned\",\n",
    "    # Эмуляция большого батча (32 * 4 = 128) для улучшения качества\n",
    "    # contrastive loss (MNRL) и экономии видеопамяти\n",
    "    per_device_train_batch_size=batch_size,  # 32\n",
    "    gradient_accumulation_steps=4,\n",
    "    # --- Параметры оптимизации ---\n",
    "    learning_rate=2e-4,  # Эмпирическая оценка. 2e-4 — \"золотой стандарт\" для обучения адаптеров LoRA.\n",
    "    lr_scheduler_type=\"cosine\",  # Плавное затухание для стабильности\n",
    "    warmup_ratio=0.05,  # Эмпирическая оценка. Для стабидизации обучения на начальном этапе.\n",
    "    weight_decay=0.01,  # Эмпирическая оценка. Для регуляризации весов модели.\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=epochs,\n",
    "    max_steps=total_steps,\n",
    "    # --- Параметры сохранения ---\n",
    "    # Сохраняем только итоговую модель\n",
    "    save_strategy=\"no\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    report_to=\"none\",\n",
    "    # --- Вычислительная оптимизация ---\n",
    "    # Оптимизатор с выгрузкой в RAM\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    # Смешанная точность (fp16) и чекпоинтинг для экономии памяти\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_checkpointing=True,\n",
    "    # Отбрасываем неполный последний батч, чтобы избежать ошибок размерности\n",
    "    dataloader_drop_last=True,\n",
    "    dataloader_num_workers=0,\n",
    "    seed=rstate,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=st_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    loss=train_loss,\n",
    ")\n",
    "\n",
    "print(\"Начинаем QLoRA-дообучение энкодера...\")\n",
    "trainer.train()\n",
    "print(\"Дообучение завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder-final-eval-explain",
   "metadata": {},
   "source": [
    "## 5. Оценка качества обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "encoder-final-eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем дообученную модель из ./rubert-tiny2-qa-finetuned...\n",
      "--- Оценка дообученной модели ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffa961876b40cb8e3088c537463b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy@1': np.float64(0.251), 'accuracy@3': np.float64(0.389), 'accuracy@5': np.float64(0.462)}\n"
     ]
    }
   ],
   "source": [
    "# 1. Загружаем дообученную модель\n",
    "finetuned_model_path = \"./rubert-tiny2-qa-finetuned\"\n",
    "print(f\"Загружаем дообученную модель из {finetuned_model_path}...\")\n",
    "finetuned_encoder_model = SentenceTransformer(finetuned_model_path)\n",
    "\n",
    "# 2. Оцениваем качество\n",
    "print(\"--- Оценка дообученной модели ---\")\n",
    "# Используем ту же функцию evaluate_model, что и для базовой модели\n",
    "finetuned_model_results = evaluate_model(finetuned_encoder_model, queries, corpus, relevant_docs)\n",
    "print(finetuned_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder-conclusions",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "Сравним результаты до и после дообучения:\n",
    "\n",
    "**Базовая модель:**\n",
    "```\n",
    "{'accuracy@1': np.float64(0.09), 'accuracy@3': np.float64(0.143), 'accuracy@5': np.float64(0.177)}\n",
    "```\n",
    "**Дообученная модель:**\n",
    "```\n",
    "{'accuracy@1': np.float64(0.251), 'accuracy@3': np.float64(0.389), 'accuracy@5': np.float64(0.462)}\n",
    "```\n",
    "**Заключение:**\n",
    "Метрики `accuracy@k` показывают, что модель стала значительно лучше сопоставлять семантическую близость вопросов и ответов. Это подтверждает, что метод дообучения QLoRA является эффективной техникой для адаптации энкодерных моделей к домен-специфичным задачам поиска, обеспечивая при этом экономию ресурсов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
